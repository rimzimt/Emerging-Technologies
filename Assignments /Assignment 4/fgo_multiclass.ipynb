{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\micha\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import random \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from random import randrange\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.layers import Activation, Flatten, Dropout, BatchNormalization\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "\n",
    "dat = pd.read_csv('fgo_multiclass_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'full_path', 'image_name', 'name', 'white', 'red',\n",
       "       'green', 'black', 'blue', 'purple', 'gold', 'silver', 'gender_Female',\n",
       "       'gender_Male', 'region_Asia', 'region_Egypt', 'region_Europe',\n",
       "       'region_Middle East', 'fighting_type_magic', 'fighting_type_melee',\n",
       "       'fighting_type_ranged', 'alignment_CE', 'alignment_CG', 'alignment_CN',\n",
       "       'alignment_LE', 'alignment_LG', 'alignment_LN', 'alignment_NE',\n",
       "       'alignment_NG', 'alignment_TN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()\n",
    "\n",
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat['image_name']\n",
    "y = dat[['white', 'red',\n",
    "       'green', 'black', 'blue', 'purple', 'gold', 'silver', 'gender_Female',\n",
    "       'gender_Male', 'region_Asia', 'region_Egypt', 'region_Europe',\n",
    "       'region_Middle East', 'fighting_type_magic', 'fighting_type_melee',\n",
    "       'fighting_type_ranged', 'alignment_CE', 'alignment_CG', 'alignment_CN',\n",
    "       'alignment_LE', 'alignment_LG', 'alignment_LN', 'alignment_NE',\n",
    "       'alignment_NG', 'alignment_TN']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['white', 'red', 'green', 'black', 'blue', 'purple', 'gold', 'silver',\n",
       "       'gender_Female', 'gender_Male', 'region_Asia', 'region_Egypt',\n",
       "       'region_Europe', 'region_Middle East', 'fighting_type_magic',\n",
       "       'fighting_type_melee', 'fighting_type_ranged', 'alignment_CE',\n",
       "       'alignment_CG', 'alignment_CN', 'alignment_LE', 'alignment_LG',\n",
       "       'alignment_LN', 'alignment_NE', 'alignment_NG', 'alignment_TN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2 4 3 9\n",
      "8 2 4 3 9\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.values.tolist()\n",
    "X_test = X_test.values.tolist()\n",
    "\n",
    "#train\n",
    "colors = ['white', 'red',\n",
    "       'green', 'black', 'blue', 'purple', 'gold', 'silver']\n",
    "color_train = y_train[colors]\n",
    "color_nodes = color_train.shape[1]\n",
    "color_train = color_train.values.tolist()\n",
    "\n",
    "gender = ['gender_Female',\n",
    "       'gender_Male']\n",
    "gender_train = y_train[gender]\n",
    "gender_nodes = gender_train.shape[1]\n",
    "gender_train = gender_train.values.tolist()\n",
    "\n",
    "region = ['region_Asia', 'region_Egypt', 'region_Europe',\n",
    "       'region_Middle East']\n",
    "region_train = y_train[region]\n",
    "region_nodes = region_train.shape[1]\n",
    "region_train = region_train.values.tolist()\n",
    "\n",
    "fighting_style = ['fighting_type_magic', 'fighting_type_melee',\n",
    "       'fighting_type_ranged']\n",
    "fighting_style_train = y_train[fighting_style]\n",
    "fighting_nodes = fighting_style_train.shape[1]\n",
    "fighting_style_train = fighting_style_train.values.tolist()\n",
    "\n",
    "alignment = ['alignment_CE', 'alignment_CG', 'alignment_CN',\n",
    "       'alignment_LE', 'alignment_LG', 'alignment_LN', 'alignment_NE',\n",
    "       'alignment_NG', 'alignment_TN']\n",
    "alignment_train = y_train[alignment]\n",
    "alignment_nodes = alignment_train.shape[1]\n",
    "alignment_train = alignment_train.values.tolist()\n",
    "\n",
    "print(color_nodes,gender_nodes,region_nodes,fighting_nodes,alignment_nodes)\n",
    "#test\n",
    "colors = ['white', 'red',\n",
    "       'green', 'black', 'blue', 'purple', 'gold', 'silver']\n",
    "color_test = y_test[colors]\n",
    "color_nodes = color_test.shape[1]\n",
    "color_test = color_test.values.tolist()\n",
    "\n",
    "gender = ['gender_Female',\n",
    "       'gender_Male']\n",
    "gender_test = y_test[gender]\n",
    "gender_nodes = gender_test.shape[1]\n",
    "gender_test = gender_test.values.tolist()\n",
    "\n",
    "region = ['region_Asia', 'region_Egypt', 'region_Europe',\n",
    "       'region_Middle East']\n",
    "region_test = y_test[region]\n",
    "region_nodes = region_test.shape[1]\n",
    "region_test = region_test.values.tolist()\n",
    "\n",
    "fighting_style = ['fighting_type_magic', 'fighting_type_melee',\n",
    "       'fighting_type_ranged']\n",
    "fighting_style_test = y_test[fighting_style]\n",
    "fighting_nodes = fighting_style_test.shape[1]\n",
    "fighting_style_test = fighting_style_test.values.tolist()\n",
    "\n",
    "alignment = ['alignment_CE', 'alignment_CG', 'alignment_CN',\n",
    "       'alignment_LE', 'alignment_LG', 'alignment_LN', 'alignment_NE',\n",
    "       'alignment_NG', 'alignment_TN']\n",
    "alignment_test = y_test[alignment]\n",
    "alignment_nodes = alignment_test.shape[1]\n",
    "alignment_test = alignment_test.values.tolist()\n",
    "\n",
    "print(color_nodes,gender_nodes,region_nodes,fighting_nodes,alignment_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initialize the number of epochs and batch size\n",
    "EPOCHS = 50\n",
    "BS = 16\n",
    "\n",
    "\n",
    "def image_generator_fgo(king_of_lists, bs, mode=\"train\", aug=None):\n",
    "    # loop indefinitely\n",
    "    \n",
    "    while True:\n",
    "        # initialize our batches of images and labels\n",
    "        images = []\n",
    "        #labels = []\n",
    "        \n",
    "        color = []\n",
    "        gender = []\n",
    "        region = []\n",
    "        fight = []\n",
    "        alignment = []\n",
    "        \n",
    "        # keep looping until we reach our batch size\n",
    "        while len(images) < bs:\n",
    "            combined_label_list = []\n",
    "            random_index = randrange(len(king_of_lists[0]))\n",
    "            img = image.load_img('images/'+king_of_lists[0][random_index],target_size=(224, 224)) #read in image\n",
    "            img = image.img_to_array(img)\n",
    "            #img = cv2.resize(img, (224, 224))\n",
    "            #F this making my own augmentations\n",
    "            #rand = random.randint(1,101)\n",
    "            #if rand < 50: \n",
    "            #    img = cv2.flip( img, 0 )# horizantal flip\n",
    "            #rand = random.randint(1,101)\n",
    "            #img = np.expand_dims(img, axis=0)\n",
    "            img = preprocess_input(img)\n",
    "            \n",
    "            #create labels\n",
    "            gender.append(king_of_lists[1][random_index]) # gender\n",
    "            region.append(np.array(king_of_lists[2][random_index])) # region\n",
    "            fight.append(np.array(king_of_lists[3][random_index])) # fighting\n",
    "            alignment.append(np.array(king_of_lists[4][random_index])) # alignment\n",
    "            color.append(np.array(king_of_lists[5][random_index])) # color\n",
    "            \n",
    "            images.append(img)\n",
    "            #labels.append(gender\n",
    "            \n",
    "        #labels = {'gender': np.array(gender), 'region': np.array(region),\n",
    "        #        'fighting_style': np.array(fight),\n",
    "        #         'alignment': np.array(alignment),'color': np.array(color)}\n",
    "        labels = [np.array(gender),np.array(region),np.array(fight),np.array(alignment), np.array(color)]\n",
    "        #labels = [gender,region,fight,alignment,color]\n",
    "        # if the data augmentation object is not None, apply it\n",
    "        #labels\n",
    "        if aug is not None:\n",
    "            (images, labels) = next(aug.flow(np.array(images),labels, batch_size=bs))\n",
    "        \n",
    "        #print(labels.shape)\n",
    "        # yield the batch to the calling function\n",
    "        yield np.array(images),  labels \n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "                         width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "train_lists = [X_train, gender_train, region_train, fighting_style_train, alignment_train, color_train]\n",
    "test_lists = [X_test, gender_test, region_test, fighting_style_test, alignment_test, color_test]\n",
    "#train_lists = [X_train, region_train, fighting_style_train, alignment_train, color_train]\n",
    "#test_lists = [X_test, region_test, fighting_style_test, alignment_test, color_test]\n",
    "# initialize both the training and testing image generators\n",
    "trainGen = image_generator_fgo(train_lists, BS, \n",
    "                               mode=\"train\", aug=None)\n",
    "testGen = image_generator_fgo(test_lists, BS, \n",
    "                              mode=\"train\", aug=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Model)                   multiple             20024384    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           8256        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           8256        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           8256        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64)           0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 2)            130         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "region (Dense)                  (None, 4)            260         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fighting_style (Dense)          (None, 3)            195         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "alignment (Dense)               (None, 9)            585         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "color (Dense)                   (None, 8)            520         dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,428,954\n",
      "Trainable params: 404,570\n",
      "Non-trainable params: 20,024,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Color Images, Multi-Label Targets\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "loss_list = [\"categorical_crossentropy\",'categorical_crossentropy',\n",
    "'categorical_crossentropy','categorical_crossentropy',\n",
    "'binary_crossentropy']\n",
    "\n",
    "test_metrics = {'gender': 'accuracy','region': 'accuracy',\n",
    "               'fighting_style': 'accuracy','alignment': 'accuracy',\n",
    "               'color': 'accuracy'}\n",
    "dd = 0.0\n",
    "import math\n",
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.01\n",
    "   drop = 0.5\n",
    "   epochs_drop = 5.0\n",
    "   lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate\n",
    "\n",
    "def multi_model(loss_list,test_metrics,dd):\n",
    "    \n",
    "    base_model = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "    #freeze all the layers\n",
    "    for layer in base_model.layers[:]:\n",
    "       layer.trainable = False\n",
    "\n",
    "    \n",
    "    model_input = Input(shape=(224, 224, 3))\n",
    "    x = base_model(model_input)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dd)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dd)(x)\n",
    "    # start passing that fully connected block output to all the \n",
    "    # different model heads\n",
    "    y1 = Dense(128, activation='relu')(x)\n",
    "    y1 = Dropout(dd)(y1)\n",
    "    y1 = Dense(64, activation='relu')(y1)\n",
    "    y1 = Dropout(dd)(y1)\n",
    "    \n",
    "    y2 = Dense(128, activation='relu')(x)\n",
    "    y2 = Dropout(dd)(y2)\n",
    "    y2 = Dense(64, activation='relu')(y2)\n",
    "    y2 = Dropout(dd)(y2)\n",
    "    \n",
    "    y3 = Dense(128, activation='relu')(x)\n",
    "    y3 = Dropout(dd)(y3)\n",
    "    y3 = Dense(64, activation='relu')(y3)\n",
    "    y3 = Dropout(dd)(y3)\n",
    "\n",
    "    y4 = Dense(128, activation='relu')(x)\n",
    "    y4 = Dropout(dd)(y4)\n",
    "    y4 = Dense(64, activation='relu')(y4)\n",
    "    y4 = Dropout(dd)(y4)\n",
    "    \n",
    "    y5 = Dense(128, activation='relu')(x)\n",
    "    y5 = Dropout(dd)(y5)\n",
    "    y5 = Dense(64, activation='relu')(y5)\n",
    "    y5 = Dropout(dd)(y5)\n",
    "    \n",
    "    #connect all the heads to their final output layers\n",
    "    y1 = Dense(gender_nodes, activation='softmax',name= 'gender')(y1)\n",
    "    y2 = Dense(region_nodes, activation='softmax',name= 'region')(y2)\n",
    "    y3 = Dense(fighting_nodes, activation='softmax',name= 'fighting_style')(y3)\n",
    "    y4 = Dense(alignment_nodes, activation='softmax',name= 'alignment')(y4)\n",
    "    y5 = Dense(color_nodes, activation='sigmoid',name= 'color')(y5)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=[ y1, y2, y3, y4, y5])\n",
    "    \n",
    "    model.compile(loss=loss_list, optimizer=SGD(lr=0.01,momentum=0.9), metrics=test_metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "multi_model = multi_model(loss_list,test_metrics,dd)\n",
    "\n",
    "multi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'gender_loss', 'region_loss', 'fighting_style_loss', 'alignment_loss', 'color_loss', 'gender_acc', 'region_acc', 'fighting_style_acc', 'alignment_acc', 'color_acc']\n"
     ]
    }
   ],
   "source": [
    "print(multi_model.metrics_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 7s 305ms/step - loss: 7.5783 - gender_loss: 1.0907 - region_loss: 1.5782 - fighting_style_loss: 1.7788 - alignment_loss: 2.3787 - color_loss: 0.7518 - gender_acc: 0.5341 - region_acc: 0.4830 - fighting_style_acc: 0.4318 - alignment_acc: 0.2244 - color_acc: 0.6154 - val_loss: 5.6298 - val_gender_loss: 0.6985 - val_region_loss: 1.2378 - val_fighting_style_loss: 1.0599 - val_alignment_loss: 1.9709 - val_color_loss: 0.6628 - val_gender_acc: 0.5938 - val_region_acc: 0.4688 - val_fighting_style_acc: 0.4062 - val_alignment_acc: 0.1875 - val_color_acc: 0.6328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.62982, saving model to models/best_run5_smaller.h5\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 5s 228ms/step - loss: 5.2329 - gender_loss: 0.7172 - region_loss: 1.0753 - fighting_style_loss: 0.9913 - alignment_loss: 1.8165 - color_loss: 0.6327 - gender_acc: 0.5199 - region_acc: 0.5511 - fighting_style_acc: 0.5085 - alignment_acc: 0.3864 - color_acc: 0.6438 - val_loss: 5.4562 - val_gender_loss: 0.6830 - val_region_loss: 1.4552 - val_fighting_style_loss: 0.8498 - val_alignment_loss: 1.8662 - val_color_loss: 0.6019 - val_gender_acc: 0.5000 - val_region_acc: 0.4688 - val_fighting_style_acc: 0.6562 - val_alignment_acc: 0.2812 - val_color_acc: 0.6602\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.62982 to 5.45616, saving model to models/best_run5_smaller.h5\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 6s 258ms/step - loss: 4.5814 - gender_loss: 0.6196 - region_loss: 0.9723 - fighting_style_loss: 0.8293 - alignment_loss: 1.5626 - color_loss: 0.5975 - gender_acc: 0.6705 - region_acc: 0.5653 - fighting_style_acc: 0.6023 - alignment_acc: 0.4801 - color_acc: 0.6861 - val_loss: 4.5417 - val_gender_loss: 0.6558 - val_region_loss: 0.8915 - val_fighting_style_loss: 0.9593 - val_alignment_loss: 1.4595 - val_color_loss: 0.5756 - val_gender_acc: 0.5938 - val_region_acc: 0.5625 - val_fighting_style_acc: 0.4688 - val_alignment_acc: 0.4375 - val_color_acc: 0.7188\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.45616 to 4.54168, saving model to models/best_run5_smaller.h5\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 5s 246ms/step - loss: 3.9242 - gender_loss: 0.5381 - region_loss: 0.7036 - fighting_style_loss: 0.6906 - alignment_loss: 1.4480 - color_loss: 0.5439 - gender_acc: 0.7102 - region_acc: 0.6903 - fighting_style_acc: 0.6676 - alignment_acc: 0.5114 - color_acc: 0.7283 - val_loss: 5.7029 - val_gender_loss: 0.4161 - val_region_loss: 1.3653 - val_fighting_style_loss: 1.2806 - val_alignment_loss: 2.0703 - val_color_loss: 0.5707 - val_gender_acc: 0.8750 - val_region_acc: 0.5000 - val_fighting_style_acc: 0.5312 - val_alignment_acc: 0.2188 - val_color_acc: 0.7344\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.54168\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 5s 244ms/step - loss: 3.6321 - gender_loss: 0.4606 - region_loss: 0.7573 - fighting_style_loss: 0.6479 - alignment_loss: 1.2190 - color_loss: 0.5474 - gender_acc: 0.7869 - region_acc: 0.6534 - fighting_style_acc: 0.7386 - alignment_acc: 0.5625 - color_acc: 0.7063 - val_loss: 4.4790 - val_gender_loss: 0.5497 - val_region_loss: 1.2843 - val_fighting_style_loss: 0.6466 - val_alignment_loss: 1.4543 - val_color_loss: 0.5441 - val_gender_acc: 0.7188 - val_region_acc: 0.5625 - val_fighting_style_acc: 0.6562 - val_alignment_acc: 0.5938 - val_color_acc: 0.7461\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.54168 to 4.47900, saving model to models/best_run5_smaller.h5\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 5s 235ms/step - loss: 2.4323 - gender_loss: 0.3439 - region_loss: 0.4553 - fighting_style_loss: 0.3804 - alignment_loss: 0.7512 - color_loss: 0.5016 - gender_acc: 0.8580 - region_acc: 0.8239 - fighting_style_acc: 0.8580 - alignment_acc: 0.7244 - color_acc: 0.7457 - val_loss: 3.0250 - val_gender_loss: 0.2992 - val_region_loss: 0.5102 - val_fighting_style_loss: 0.7078 - val_alignment_loss: 1.0185 - val_color_loss: 0.4893 - val_gender_acc: 0.8125 - val_region_acc: 0.8125 - val_fighting_style_acc: 0.6562 - val_alignment_acc: 0.5625 - val_color_acc: 0.7500\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.47900 to 3.02502, saving model to models/best_run5_smaller.h5\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 5s 249ms/step - loss: 2.3080 - gender_loss: 0.3554 - region_loss: 0.3934 - fighting_style_loss: 0.3373 - alignment_loss: 0.7437 - color_loss: 0.4782 - gender_acc: 0.8409 - region_acc: 0.8153 - fighting_style_acc: 0.8523 - alignment_acc: 0.7131 - color_acc: 0.7646 - val_loss: 4.7920 - val_gender_loss: 0.4120 - val_region_loss: 0.8651 - val_fighting_style_loss: 0.9444 - val_alignment_loss: 2.0258 - val_color_loss: 0.5448 - val_gender_acc: 0.8125 - val_region_acc: 0.5625 - val_fighting_style_acc: 0.6875 - val_alignment_acc: 0.2188 - val_color_acc: 0.7305\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.02502\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 5s 247ms/step - loss: 1.9369 - gender_loss: 0.3151 - region_loss: 0.3239 - fighting_style_loss: 0.2892 - alignment_loss: 0.5565 - color_loss: 0.4523 - gender_acc: 0.8580 - region_acc: 0.8608 - fighting_style_acc: 0.8892 - alignment_acc: 0.8324 - color_acc: 0.7777 - val_loss: 4.5991 - val_gender_loss: 0.6046 - val_region_loss: 0.6702 - val_fighting_style_loss: 0.7676 - val_alignment_loss: 2.0011 - val_color_loss: 0.5556 - val_gender_acc: 0.7812 - val_region_acc: 0.7500 - val_fighting_style_acc: 0.6562 - val_alignment_acc: 0.4375 - val_color_acc: 0.6992\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.02502\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 6s 257ms/step - loss: 1.4783 - gender_loss: 0.2442 - region_loss: 0.2048 - fighting_style_loss: 0.1705 - alignment_loss: 0.4184 - color_loss: 0.4405 - gender_acc: 0.8892 - region_acc: 0.9205 - fighting_style_acc: 0.9432 - alignment_acc: 0.8608 - color_acc: 0.7923 - val_loss: 5.2060 - val_gender_loss: 0.4580 - val_region_loss: 1.0028 - val_fighting_style_loss: 1.2047 - val_alignment_loss: 1.9746 - val_color_loss: 0.5659 - val_gender_acc: 0.8438 - val_region_acc: 0.6875 - val_fighting_style_acc: 0.6250 - val_alignment_acc: 0.5000 - val_color_acc: 0.7422\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.02502\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 6s 270ms/step - loss: 1.4735 - gender_loss: 0.1628 - region_loss: 0.2274 - fighting_style_loss: 0.2136 - alignment_loss: 0.4479 - color_loss: 0.4219 - gender_acc: 0.9261 - region_acc: 0.9119 - fighting_style_acc: 0.9375 - alignment_acc: 0.8580 - color_acc: 0.8026 - val_loss: 2.7943 - val_gender_loss: 0.4151 - val_region_loss: 0.4454 - val_fighting_style_loss: 0.6862 - val_alignment_loss: 0.6991 - val_color_loss: 0.5484 - val_gender_acc: 0.8750 - val_region_acc: 0.8750 - val_fighting_style_acc: 0.8125 - val_alignment_acc: 0.7500 - val_color_acc: 0.7539\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.02502 to 2.79427, saving model to models/best_run5_smaller.h5\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 5s 225ms/step - loss: 0.8731 - gender_loss: 0.0960 - region_loss: 0.0943 - fighting_style_loss: 0.0960 - alignment_loss: 0.2052 - color_loss: 0.3816 - gender_acc: 0.9688 - region_acc: 0.9688 - fighting_style_acc: 0.9602 - alignment_acc: 0.9403 - color_acc: 0.8228 - val_loss: 3.6796 - val_gender_loss: 0.5991 - val_region_loss: 0.7885 - val_fighting_style_loss: 0.6303 - val_alignment_loss: 1.1176 - val_color_loss: 0.5442 - val_gender_acc: 0.8438 - val_region_acc: 0.7188 - val_fighting_style_acc: 0.7812 - val_alignment_acc: 0.7188 - val_color_acc: 0.7539\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.79427\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 6s 268ms/step - loss: 0.6946 - gender_loss: 0.0897 - region_loss: 0.0628 - fighting_style_loss: 0.0589 - alignment_loss: 0.1280 - color_loss: 0.3552 - gender_acc: 0.9716 - region_acc: 0.9801 - fighting_style_acc: 0.9744 - alignment_acc: 0.9744 - color_acc: 0.8327 - val_loss: 3.7664 - val_gender_loss: 0.5174 - val_region_loss: 1.0387 - val_fighting_style_loss: 0.6433 - val_alignment_loss: 1.1256 - val_color_loss: 0.4415 - val_gender_acc: 0.8438 - val_region_acc: 0.5938 - val_fighting_style_acc: 0.7188 - val_alignment_acc: 0.6875 - val_color_acc: 0.7930\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.79427\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 5s 231ms/step - loss: 0.5982 - gender_loss: 0.0546 - region_loss: 0.0858 - fighting_style_loss: 0.0299 - alignment_loss: 0.0710 - color_loss: 0.3569 - gender_acc: 0.9830 - region_acc: 0.9744 - fighting_style_acc: 1.0000 - alignment_acc: 0.9773 - color_acc: 0.8388 - val_loss: 4.4931 - val_gender_loss: 0.2977 - val_region_loss: 1.0417 - val_fighting_style_loss: 0.9270 - val_alignment_loss: 1.7323 - val_color_loss: 0.4945 - val_gender_acc: 0.9062 - val_region_acc: 0.6562 - val_fighting_style_acc: 0.5938 - val_alignment_acc: 0.5000 - val_color_acc: 0.7539\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.79427\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 6s 265ms/step - loss: 0.4681 - gender_loss: 0.0444 - region_loss: 0.0329 - fighting_style_loss: 0.0191 - alignment_loss: 0.0548 - color_loss: 0.3168 - gender_acc: 0.9886 - region_acc: 0.9915 - fighting_style_acc: 0.9943 - alignment_acc: 0.9858 - color_acc: 0.8633 - val_loss: 3.0838 - val_gender_loss: 0.3802 - val_region_loss: 0.6491 - val_fighting_style_loss: 0.6512 - val_alignment_loss: 0.9622 - val_color_loss: 0.4411 - val_gender_acc: 0.8750 - val_region_acc: 0.7812 - val_fighting_style_acc: 0.7500 - val_alignment_acc: 0.7188 - val_color_acc: 0.7891\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.79427\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 5s 236ms/step - loss: 0.4185 - gender_loss: 0.0287 - region_loss: 0.0193 - fighting_style_loss: 0.0214 - alignment_loss: 0.0382 - color_loss: 0.3109 - gender_acc: 0.9943 - region_acc: 1.0000 - fighting_style_acc: 0.9943 - alignment_acc: 0.9886 - color_acc: 0.8683 - val_loss: 3.9093 - val_gender_loss: 0.1269 - val_region_loss: 1.1416 - val_fighting_style_loss: 0.9117 - val_alignment_loss: 1.1995 - val_color_loss: 0.5295 - val_gender_acc: 0.9062 - val_region_acc: 0.6875 - val_fighting_style_acc: 0.6875 - val_alignment_acc: 0.5625 - val_color_acc: 0.7500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.79427\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 5s 238ms/step - loss: 0.3629 - gender_loss: 0.0135 - region_loss: 0.0253 - fighting_style_loss: 0.0072 - alignment_loss: 0.0259 - color_loss: 0.2910 - gender_acc: 1.0000 - region_acc: 0.9943 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.8743 - val_loss: 3.5094 - val_gender_loss: 0.5501 - val_region_loss: 0.7154 - val_fighting_style_loss: 0.3942 - val_alignment_loss: 1.3729 - val_color_loss: 0.4768 - val_gender_acc: 0.8438 - val_region_acc: 0.8125 - val_fighting_style_acc: 0.8750 - val_alignment_acc: 0.6875 - val_color_acc: 0.7578\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.79427\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 6s 261ms/step - loss: 0.3482 - gender_loss: 0.0081 - region_loss: 0.0148 - fighting_style_loss: 0.0065 - alignment_loss: 0.0179 - color_loss: 0.3009 - gender_acc: 1.0000 - region_acc: 0.9972 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.8736 - val_loss: 4.2935 - val_gender_loss: 0.3967 - val_region_loss: 0.6776 - val_fighting_style_loss: 1.4614 - val_alignment_loss: 1.2650 - val_color_loss: 0.4928 - val_gender_acc: 0.8750 - val_region_acc: 0.7812 - val_fighting_style_acc: 0.6250 - val_alignment_acc: 0.5625 - val_color_acc: 0.7930\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.79427\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 6s 286ms/step - loss: 0.3537 - gender_loss: 0.0100 - region_loss: 0.0226 - fighting_style_loss: 0.0059 - alignment_loss: 0.0198 - color_loss: 0.2954 - gender_acc: 0.9943 - region_acc: 0.9915 - fighting_style_acc: 1.0000 - alignment_acc: 0.9972 - color_acc: 0.8789 - val_loss: 3.4302 - val_gender_loss: 0.1444 - val_region_loss: 0.8222 - val_fighting_style_loss: 0.8424 - val_alignment_loss: 1.1362 - val_color_loss: 0.4849 - val_gender_acc: 0.9688 - val_region_acc: 0.7500 - val_fighting_style_acc: 0.8125 - val_alignment_acc: 0.6562 - val_color_acc: 0.8008\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.79427\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 0.3199 - gender_loss: 0.0072 - region_loss: 0.0094 - fighting_style_loss: 0.0039 - alignment_loss: 0.0194 - color_loss: 0.2800 - gender_acc: 1.0000 - region_acc: 1.0000 - fighting_style_acc: 1.0000 - alignment_acc: 0.9972 - color_acc: 0.8803 - val_loss: 3.6155 - val_gender_loss: 0.8511 - val_region_loss: 0.5025 - val_fighting_style_loss: 0.7163 - val_alignment_loss: 0.9803 - val_color_loss: 0.5653 - val_gender_acc: 0.7500 - val_region_acc: 0.8750 - val_fighting_style_acc: 0.8125 - val_alignment_acc: 0.6875 - val_color_acc: 0.7461\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.79427\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 6s 251ms/step - loss: 0.3182 - gender_loss: 0.0052 - region_loss: 0.0162 - fighting_style_loss: 0.0057 - alignment_loss: 0.0153 - color_loss: 0.2757 - gender_acc: 1.0000 - region_acc: 0.9943 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.8878 - val_loss: 4.5030 - val_gender_loss: 0.5215 - val_region_loss: 0.8434 - val_fighting_style_loss: 1.1539 - val_alignment_loss: 1.4201 - val_color_loss: 0.5641 - val_gender_acc: 0.8438 - val_region_acc: 0.6875 - val_fighting_style_acc: 0.6875 - val_alignment_acc: 0.5312 - val_color_acc: 0.7539\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.79427\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 5s 249ms/step - loss: 0.3092 - gender_loss: 0.0125 - region_loss: 0.0094 - fighting_style_loss: 0.0038 - alignment_loss: 0.0198 - color_loss: 0.2638 - gender_acc: 0.9972 - region_acc: 0.9972 - fighting_style_acc: 1.0000 - alignment_acc: 0.9972 - color_acc: 0.8974 - val_loss: 3.6739 - val_gender_loss: 0.3759 - val_region_loss: 0.5702 - val_fighting_style_loss: 1.0868 - val_alignment_loss: 1.1612 - val_color_loss: 0.4798 - val_gender_acc: 0.9062 - val_region_acc: 0.7812 - val_fighting_style_acc: 0.5938 - val_alignment_acc: 0.5938 - val_color_acc: 0.7773\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.79427\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 5s 229ms/step - loss: 0.2923 - gender_loss: 0.0099 - region_loss: 0.0072 - fighting_style_loss: 0.0024 - alignment_loss: 0.0164 - color_loss: 0.2565 - gender_acc: 0.9972 - region_acc: 1.0000 - fighting_style_acc: 1.0000 - alignment_acc: 0.9972 - color_acc: 0.8991 - val_loss: 4.2237 - val_gender_loss: 0.0642 - val_region_loss: 0.9315 - val_fighting_style_loss: 0.7865 - val_alignment_loss: 1.9399 - val_color_loss: 0.5016 - val_gender_acc: 0.9688 - val_region_acc: 0.7500 - val_fighting_style_acc: 0.6875 - val_alignment_acc: 0.5312 - val_color_acc: 0.7695\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.79427\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 6s 259ms/step - loss: 0.2938 - gender_loss: 0.0050 - region_loss: 0.0064 - fighting_style_loss: 0.0034 - alignment_loss: 0.0091 - color_loss: 0.2699 - gender_acc: 1.0000 - region_acc: 1.0000 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.8967 - val_loss: 2.6602 - val_gender_loss: 0.0262 - val_region_loss: 0.8129 - val_fighting_style_loss: 0.6140 - val_alignment_loss: 0.6923 - val_color_loss: 0.5147 - val_gender_acc: 1.0000 - val_region_acc: 0.7500 - val_fighting_style_acc: 0.7500 - val_alignment_acc: 0.6562 - val_color_acc: 0.7461\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.79427 to 2.66019, saving model to models/best_run5_smaller.h5\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 6s 269ms/step - loss: 0.2921 - gender_loss: 0.0124 - region_loss: 0.0058 - fighting_style_loss: 0.0024 - alignment_loss: 0.0189 - color_loss: 0.2526 - gender_acc: 0.9943 - region_acc: 1.0000 - fighting_style_acc: 1.0000 - alignment_acc: 0.9943 - color_acc: 0.8956 - val_loss: 4.0458 - val_gender_loss: 0.1888 - val_region_loss: 0.8708 - val_fighting_style_loss: 0.9869 - val_alignment_loss: 1.4473 - val_color_loss: 0.5521 - val_gender_acc: 0.9375 - val_region_acc: 0.7188 - val_fighting_style_acc: 0.6875 - val_alignment_acc: 0.6250 - val_color_acc: 0.7539\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66019\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 6s 258ms/step - loss: 0.3114 - gender_loss: 0.0112 - region_loss: 0.0062 - fighting_style_loss: 0.0035 - alignment_loss: 0.0157 - color_loss: 0.2749 - gender_acc: 0.9972 - region_acc: 1.0000 - fighting_style_acc: 1.0000 - alignment_acc: 0.9943 - color_acc: 0.8896 - val_loss: 2.3096 - val_gender_loss: 0.4706 - val_region_loss: 0.3397 - val_fighting_style_loss: 0.3780 - val_alignment_loss: 0.6421 - val_color_loss: 0.4792 - val_gender_acc: 0.9062 - val_region_acc: 0.8438 - val_fighting_style_acc: 0.8125 - val_alignment_acc: 0.7188 - val_color_acc: 0.7812\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.66019 to 2.30957, saving model to models/best_run5_smaller.h5\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.2711 - gender_loss: 0.0053 - region_loss: 0.0052 - fighting_style_loss: 0.0024 - alignment_loss: 0.0100 - color_loss: 0.2481 - gender_acc: 1.0000 - region_acc: 1.0000 - fighting_style_acc: 1.0000 - alignment_acc: 0.9972 - color_acc: 0.8949 - val_loss: 5.0534 - val_gender_loss: 0.8683 - val_region_loss: 1.1963 - val_fighting_style_loss: 0.8168 - val_alignment_loss: 1.6199 - val_color_loss: 0.5522 - val_gender_acc: 0.7812 - val_region_acc: 0.6875 - val_fighting_style_acc: 0.7188 - val_alignment_acc: 0.5312 - val_color_acc: 0.7461\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.30957\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 5s 231ms/step - loss: 0.2988 - gender_loss: 0.0045 - region_loss: 0.0148 - fighting_style_loss: 0.0040 - alignment_loss: 0.0079 - color_loss: 0.2676 - gender_acc: 1.0000 - region_acc: 0.9915 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.8917 - val_loss: 5.1122 - val_gender_loss: 1.0298 - val_region_loss: 0.8216 - val_fighting_style_loss: 1.2134 - val_alignment_loss: 1.5504 - val_color_loss: 0.4971 - val_gender_acc: 0.7812 - val_region_acc: 0.6875 - val_fighting_style_acc: 0.6562 - val_alignment_acc: 0.6562 - val_color_acc: 0.7422\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.30957\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 6s 256ms/step - loss: 0.3088 - gender_loss: 0.0068 - region_loss: 0.0103 - fighting_style_loss: 0.0034 - alignment_loss: 0.0172 - color_loss: 0.2710 - gender_acc: 1.0000 - region_acc: 0.9972 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.8899 - val_loss: 4.1369 - val_gender_loss: 0.3498 - val_region_loss: 0.9103 - val_fighting_style_loss: 0.8875 - val_alignment_loss: 1.3767 - val_color_loss: 0.6126 - val_gender_acc: 0.9062 - val_region_acc: 0.6875 - val_fighting_style_acc: 0.8125 - val_alignment_acc: 0.5625 - val_color_acc: 0.7383\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.30957\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 5s 223ms/step - loss: 0.2720 - gender_loss: 0.0050 - region_loss: 0.0069 - fighting_style_loss: 0.0033 - alignment_loss: 0.0155 - color_loss: 0.2413 - gender_acc: 1.0000 - region_acc: 0.9972 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.9080 - val_loss: 4.3044 - val_gender_loss: 0.6007 - val_region_loss: 0.4386 - val_fighting_style_loss: 1.2351 - val_alignment_loss: 1.5001 - val_color_loss: 0.5299 - val_gender_acc: 0.9062 - val_region_acc: 0.8438 - val_fighting_style_acc: 0.6562 - val_alignment_acc: 0.5312 - val_color_acc: 0.7695\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.30957\n",
      "Epoch 30/50\n",
      "11/22 [==============>...............] - ETA: 1s - loss: 0.2789 - gender_loss: 0.0046 - region_loss: 0.0036 - fighting_style_loss: 0.0048 - alignment_loss: 0.0062 - color_loss: 0.2598 - gender_acc: 1.0000 - region_acc: 1.0000 - fighting_style_acc: 1.0000 - alignment_acc: 1.0000 - color_acc: 0.8849"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('models/best_run5_smaller.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [checkpoint,lrate]\n",
    "multi_model.fit_generator(trainGen,steps_per_epoch=len(X_train) // BS,\n",
    "                    validation_data=testGen,\n",
    "                    validation_steps=len(X_test) // BS,\n",
    "                    epochs=EPOCHS,callbacks=callbacks_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
