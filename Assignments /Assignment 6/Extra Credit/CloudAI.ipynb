{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CloudAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "environment": {
      "name": "tf2-gpu.2-1.m59",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m59"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNiqq_kN0okj",
        "outputId": "d52ce242-c9da-43b0-b92f-34bdb382654e"
      },
      "source": [
        "# Install tfx and kfp Python packages.\n",
        "import sys\n",
        "!{sys.executable} -m pip install --user --upgrade -q tfx==0.23.0\n",
        "!{sys.executable} -m pip install --user --upgrade -q kfp==1.0.0\n",
        "# Download skaffold and set it executable.\n",
        "!curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold && mv skaffold /home/jupyter/.local/bin/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m  WARNING: The script plasma_store is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script gen_client is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script tensorboard is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script tfx is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "witwidget 1.7.0 requires oauth2client>=4.1.3, but you'll have oauth2client 3.0.0 which is incompatible.\n",
            "tensorflow 2.3.1 requires numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\n",
            "tensorflow-io 0.11.0 requires tensorflow==2.1.0, but you'll have tensorflow 2.3.1 which is incompatible.\n",
            "pandas-profiling 2.8.0 requires visions[type_image_path]==0.4.4, but you'll have visions 0.6.4 which is incompatible.\n",
            "explainable-ai-sdk 1.1.0 requires numpy<1.19.0, but you'll have numpy 1.19.4 which is incompatible.\n",
            "apache-beam 2.25.0 requires httplib2<0.18.0,>=0.8, but you'll have httplib2 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[33m  WARNING: The script strip-hints is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts dsl-compile and kfp are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 47.2M  100 47.2M    0     0  90.3M      0 --:--:-- --:--:-- --:--:-- 90.3M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ncix2Q0okm",
        "outputId": "0c76bcc2-be4a-403a-9abf-0540fe8583d5"
      },
      "source": [
        "# Set `PATH` to include user python binary directory and a directory containing `skaffold`.\n",
        "PATH=%env PATH\n",
        "%env PATH={PATH}:/home/jupyter/.local/bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAIoKMNG0okq",
        "outputId": "6268ef03-1883-482f-ab07-eea588dae58f"
      },
      "source": [
        "!python3 -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFX version: 0.23.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw3nsooU0okv",
        "outputId": "59ffbd0a-95c7-4b8c-9306-7042b17ff8b5"
      },
      "source": [
        "# Read GCP project id from env.\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
        "%env GOOGLE_CLOUD_PROJECT={GOOGLE_CLOUD_PROJECT}\n",
        "print(\"GCP project ID:\" + GOOGLE_CLOUD_PROJECT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: GOOGLE_CLOUD_PROJECT=wise-key-298220\n",
            "GCP project ID:wise-key-298220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzqEQORV0oky"
      },
      "source": [
        "# This refers to the KFP cluster endpoint\n",
        "ENDPOINT='https://6f1d598dc9d8bc9c-dot-us-central2.pipelines.googleusercontent.com/#/start' # Enter your ENDPOINT here.\n",
        "if not ENDPOINT:\n",
        "    from absl import logging\n",
        "    logging.error('Set your ENDPOINT in this cell.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ztxXOVD0ok4"
      },
      "source": [
        "# Docker image name for the pipeline image.\n",
        "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIPlt-700ok-"
      },
      "source": [
        "PIPELINE_NAME=\"my_pipeline\"\n",
        "import os\n",
        "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"),\"imported\",PIPELINE_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLXpTTjU0olD",
        "outputId": "b10ec33c-fa5a-4002-a132-e2ae3f119134"
      },
      "source": [
        "!tfx template copy \\\n",
        "  --pipeline-name={PIPELINE_NAME} \\\n",
        "  --destination-path={PROJECT_DIR} \\\n",
        "  --model=taxi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:07:53.076477: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:07:53.076529: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Copying taxi pipeline template\n",
            "__init__.py -> /home/jupyter/imported/my_pipeline/__init__.py\n",
            "__init__.py -> /home/jupyter/imported/my_pipeline/models/keras/__init__.py\n",
            "model.py -> /home/jupyter/imported/my_pipeline/models/keras/model.py\n",
            "model_test.py -> /home/jupyter/imported/my_pipeline/models/keras/model_test.py\n",
            "constants.py -> /home/jupyter/imported/my_pipeline/models/keras/constants.py\n",
            "__init__.py -> /home/jupyter/imported/my_pipeline/models/__init__.py\n",
            "preprocessing.py -> /home/jupyter/imported/my_pipeline/models/preprocessing.py\n",
            "features.py -> /home/jupyter/imported/my_pipeline/models/features.py\n",
            "__init__.py -> /home/jupyter/imported/my_pipeline/models/estimator/__init__.py\n",
            "model.py -> /home/jupyter/imported/my_pipeline/models/estimator/model.py\n",
            "model_test.py -> /home/jupyter/imported/my_pipeline/models/estimator/model_test.py\n",
            "constants.py -> /home/jupyter/imported/my_pipeline/models/estimator/constants.py\n",
            "features_test.py -> /home/jupyter/imported/my_pipeline/models/features_test.py\n",
            "preprocessing_test.py -> /home/jupyter/imported/my_pipeline/models/preprocessing_test.py\n",
            "pipeline.py -> /home/jupyter/imported/my_pipeline/pipeline/pipeline.py\n",
            "configs.py -> /home/jupyter/imported/my_pipeline/pipeline/configs.py\n",
            "__init__.py -> /home/jupyter/imported/my_pipeline/pipeline/__init__.py\n",
            "kubeflow_dag_runner.py -> /home/jupyter/imported/my_pipeline/kubeflow_dag_runner.py\n",
            ".gitignore -> /home/jupyter/imported/my_pipeline/.gitignore\n",
            "model_analysis.ipynb -> /home/jupyter/imported/my_pipeline/model_analysis.ipynb\n",
            "data_validation.ipynb -> /home/jupyter/imported/my_pipeline/data_validation.ipynb\n",
            "beam_dag_runner.py -> /home/jupyter/imported/my_pipeline/beam_dag_runner.py\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P-HljcU0olI",
        "outputId": "78576a60-facc-44f7-f945-0befeaabda8c"
      },
      "source": [
        "%cd {PROJECT_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jupyter/imported/my_pipeline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0cMdE2Z0olU",
        "outputId": "fc5120c4-9702-489e-e2a0-1d26b86f9073"
      },
      "source": [
        "!{sys.executable} -m models.features_test\n",
        "!{sys.executable} -m models.keras.model_test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:08:41.526428: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:08:41.526482: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "Running tests under Python 3.7.8: /opt/conda/bin/python\n",
            "[ RUN      ] FeaturesTest.testNumberOfBucketFeatureBucketCount\n",
            "INFO:tensorflow:time(__main__.FeaturesTest.testNumberOfBucketFeatureBucketCount): 0.0s\n",
            "I1210 23:08:43.297006 139682405955392 test_util.py:1973] time(__main__.FeaturesTest.testNumberOfBucketFeatureBucketCount): 0.0s\n",
            "[       OK ] FeaturesTest.testNumberOfBucketFeatureBucketCount\n",
            "[ RUN      ] FeaturesTest.testTransformedNames\n",
            "INFO:tensorflow:time(__main__.FeaturesTest.testTransformedNames): 0.0s\n",
            "I1210 23:08:43.297590 139682405955392 test_util.py:1973] time(__main__.FeaturesTest.testTransformedNames): 0.0s\n",
            "[       OK ] FeaturesTest.testTransformedNames\n",
            "[ RUN      ] FeaturesTest.test_session\n",
            "[  SKIPPED ] FeaturesTest.test_session\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.001s\n",
            "\n",
            "OK (skipped=1)\n",
            "2020-12-10 23:08:44.453605: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:08:44.453656: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "Running tests under Python 3.7.8: /opt/conda/bin/python\n",
            "[ RUN      ] ModelTest.testBuildKerasModel\n",
            "2020-12-10 23:08:46.275712: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:08:46.275775: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2020-12-10 23:08:46.275826: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tensorflow-2-1-20201210-145329): /proc/driver/nvidia/version does not exist\n",
            "2020-12-10 23:08:46.276103: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-12-10 23:08:46.288076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200140000 Hz\n",
            "2020-12-10 23:08:46.288847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561a9e0792f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-10 23:08:46.288911: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "I1210 23:08:46.379731 140427316004672 layer_utils.py:192] Model: \"functional_1\"\n",
            "I1210 23:08:46.379942 140427316004672 layer_utils.py:193] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.380052 140427316004672 layer_utils.py:190] Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "I1210 23:08:46.380123 140427316004672 layer_utils.py:195] ==================================================================================================\n",
            "I1210 23:08:46.380378 140427316004672 layer_utils.py:190] pickup_latitude_xf (InputLayer) [(None,)]            0                                            \n",
            "I1210 23:08:46.380501 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.380694 140427316004672 layer_utils.py:190] trip_miles_xf (InputLayer)      [(None,)]            0                                            \n",
            "I1210 23:08:46.380792 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.380983 140427316004672 layer_utils.py:190] trip_start_hour_xf (InputLayer) [(None,)]            0                                            \n",
            "I1210 23:08:46.381068 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.381340 140427316004672 layer_utils.py:190] dense_features (DenseFeatures)  (None, 1)            0           pickup_latitude_xf[0][0]         \n",
            "I1210 23:08:46.381458 140427316004672 layer_utils.py:190]                                                                  trip_miles_xf[0][0]              \n",
            "I1210 23:08:46.381546 140427316004672 layer_utils.py:190]                                                                  trip_start_hour_xf[0][0]         \n",
            "I1210 23:08:46.381616 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.381925 140427316004672 layer_utils.py:190] dense (Dense)                   (None, 1)            2           dense_features[0][0]             \n",
            "I1210 23:08:46.382030 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.382288 140427316004672 layer_utils.py:190] dense_1 (Dense)                 (None, 1)            2           dense[0][0]                      \n",
            "I1210 23:08:46.382398 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.382681 140427316004672 layer_utils.py:190] dense_features_1 (DenseFeatures (None, 34)           0           pickup_latitude_xf[0][0]         \n",
            "I1210 23:08:46.382776 140427316004672 layer_utils.py:190]                                                                  trip_miles_xf[0][0]              \n",
            "I1210 23:08:46.382869 140427316004672 layer_utils.py:190]                                                                  trip_start_hour_xf[0][0]         \n",
            "I1210 23:08:46.382942 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.383114 140427316004672 layer_utils.py:190] concatenate (Concatenate)       (None, 35)           0           dense_1[0][0]                    \n",
            "I1210 23:08:46.383200 140427316004672 layer_utils.py:190]                                                                  dense_features_1[0][0]           \n",
            "I1210 23:08:46.383289 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.383532 140427316004672 layer_utils.py:190] dense_2 (Dense)                 (None, 1)            36          concatenate[0][0]                \n",
            "I1210 23:08:46.383636 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.383872 140427316004672 layer_utils.py:190] tf_op_layer_Squeeze (TensorFlow [(None,)]            0           dense_2[0][0]                    \n",
            "I1210 23:08:46.383974 140427316004672 layer_utils.py:257] ==================================================================================================\n",
            "I1210 23:08:46.384629 140427316004672 layer_utils.py:268] Total params: 40\n",
            "I1210 23:08:46.385219 140427316004672 layer_utils.py:269] Trainable params: 40\n",
            "I1210 23:08:46.385334 140427316004672 layer_utils.py:270] Non-trainable params: 0\n",
            "I1210 23:08:46.385416 140427316004672 layer_utils.py:271] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.480384 140427316004672 layer_utils.py:192] Model: \"functional_3\"\n",
            "I1210 23:08:46.480569 140427316004672 layer_utils.py:193] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.480668 140427316004672 layer_utils.py:190] Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "I1210 23:08:46.480735 140427316004672 layer_utils.py:195] ==================================================================================================\n",
            "I1210 23:08:46.480995 140427316004672 layer_utils.py:190] pickup_latitude_xf (InputLayer) [(None,)]            0                                            \n",
            "I1210 23:08:46.481128 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.481365 140427316004672 layer_utils.py:190] trip_miles_xf (InputLayer)      [(None,)]            0                                            \n",
            "I1210 23:08:46.481464 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.481652 140427316004672 layer_utils.py:190] trip_start_hour_xf (InputLayer) [(None,)]            0                                            \n",
            "I1210 23:08:46.481732 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.481981 140427316004672 layer_utils.py:190] dense_features_2 (DenseFeatures (None, 1)            0           pickup_latitude_xf[0][0]         \n",
            "I1210 23:08:46.482090 140427316004672 layer_utils.py:190]                                                                  trip_miles_xf[0][0]              \n",
            "I1210 23:08:46.482178 140427316004672 layer_utils.py:190]                                                                  trip_start_hour_xf[0][0]         \n",
            "I1210 23:08:46.482256 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.482538 140427316004672 layer_utils.py:190] dense_3 (Dense)                 (None, 1)            2           dense_features_2[0][0]           \n",
            "I1210 23:08:46.482639 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.482882 140427316004672 layer_utils.py:190] dense_features_3 (DenseFeatures (None, 34)           0           pickup_latitude_xf[0][0]         \n",
            "I1210 23:08:46.482992 140427316004672 layer_utils.py:190]                                                                  trip_miles_xf[0][0]              \n",
            "I1210 23:08:46.483078 140427316004672 layer_utils.py:190]                                                                  trip_start_hour_xf[0][0]         \n",
            "I1210 23:08:46.483391 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.483727 140427316004672 layer_utils.py:190] concatenate_1 (Concatenate)     (None, 35)           0           dense_3[0][0]                    \n",
            "I1210 23:08:46.483880 140427316004672 layer_utils.py:190]                                                                  dense_features_3[0][0]           \n",
            "I1210 23:08:46.483971 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.484247 140427316004672 layer_utils.py:190] dense_4 (Dense)                 (None, 1)            36          concatenate_1[0][0]              \n",
            "I1210 23:08:46.484368 140427316004672 layer_utils.py:259] __________________________________________________________________________________________________\n",
            "I1210 23:08:46.484646 140427316004672 layer_utils.py:190] tf_op_layer_Squeeze_1 (TensorFl [(None,)]            0           dense_4[0][0]                    \n",
            "I1210 23:08:46.484736 140427316004672 layer_utils.py:257] ==================================================================================================\n",
            "I1210 23:08:46.485294 140427316004672 layer_utils.py:268] Total params: 38\n",
            "I1210 23:08:46.485396 140427316004672 layer_utils.py:269] Trainable params: 38\n",
            "I1210 23:08:46.485481 140427316004672 layer_utils.py:270] Non-trainable params: 0\n",
            "I1210 23:08:46.485553 140427316004672 layer_utils.py:271] __________________________________________________________________________________________________\n",
            "INFO:tensorflow:time(__main__.ModelTest.testBuildKerasModel): 0.24s\n",
            "I1210 23:08:46.486206 140427316004672 test_util.py:1973] time(__main__.ModelTest.testBuildKerasModel): 0.24s\n",
            "[       OK ] ModelTest.testBuildKerasModel\n",
            "[ RUN      ] ModelTest.test_session\n",
            "[  SKIPPED ] ModelTest.test_session\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.236s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW-dSHW-TSdc",
        "outputId": "dba20762-bef0-468e-8bf3-d87893a28efa"
      },
      "source": [
        "!gsutil cp data/data.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/tfx-template/data/data.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://data/data.csv [Content-Type=text/csv]...\n",
            "/ [1 files][  1.9 MiB/  1.9 MiB]                                                \n",
            "Operation completed over 1 objects/1.9 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOU7zQof0olf",
        "outputId": "5ea2aff9-3599-4008-ded8-e1a63122aad8"
      },
      "source": [
        "!tfx pipeline create  \\\n",
        "--pipeline-path=kubeflow_dag_runner.py \\\n",
        "--endpoint={ENDPOINT} \\\n",
        "--build-target-image={CUSTOM_TFX_IMAGE}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:15:20.870644: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:15:20.870697: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Creating pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Reading build spec from build.yaml\n",
            "Target image gcr.io/wise-key-298220/tfx-pipeline is not used. If the build spec is provided, update the target image in the build spec file build.yaml.\n",
            "[Skaffold] Generating tags...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline -> gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] Checking cache...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline: Not found. Building\n",
            "[Skaffold] Building [gcr.io/wise-key-298220/tfx-pipeline]...\n",
            "Sending build context to Docker daemon  2.066MBon    534kB\n",
            "[Skaffold] Step 1/4 : FROM tensorflow/tfx:0.23.0\n",
            "[Skaffold]  ---> f8355268ae44\n",
            "[Skaffold] Step 2/4 : WORKDIR /pipeline\n",
            "[Skaffold]  ---> Using cache\n",
            "[Skaffold]  ---> 442cedb2b308\n",
            "[Skaffold] Step 3/4 : COPY ./ ./\n",
            "[Skaffold]  ---> e01ea2285365\n",
            "[Skaffold] Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
            "[Skaffold]  ---> Running in 363ab2c00c2b\n",
            "[Skaffold]  ---> ba5c53c48b02\n",
            "[Skaffold] Successfully built ba5c53c48b02\n",
            "[Skaffold] Successfully tagged gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] The push refers to repository [gcr.io/wise-key-298220/tfx-pipeline]\n",
            "[Skaffold] d897a7e28378: Preparing\n",
            "[Skaffold] 291bb236dc3f: Preparing\n",
            "[Skaffold] 9042e84a180f: Preparing\n",
            "[Skaffold] 4f874315440c: Preparing\n",
            "[Skaffold] f13a156e38fd: Preparing\n",
            "[Skaffold] 572b4b19939e: Preparing\n",
            "[Skaffold] d8bc156b2e76: Preparing\n",
            "[Skaffold] 4058ae03fa32: Preparing\n",
            "[Skaffold] e3437c61d457: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] 54b00d861a7a: Preparing\n",
            "[Skaffold] c547358928ab: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] c4e66be694ce: Preparing\n",
            "[Skaffold] 47cc65c6dd57: Preparing\n",
            "[Skaffold] 572b4b19939e: Waiting\n",
            "[Skaffold] d8bc156b2e76: Waiting\n",
            "[Skaffold] 4058ae03fa32: Waiting\n",
            "[Skaffold] e3437c61d457: Waiting\n",
            "[Skaffold] 84ff92691f90: Waiting\n",
            "[Skaffold] 54b00d861a7a: Waiting\n",
            "[Skaffold] c547358928ab: Waiting\n",
            "[Skaffold] c4e66be694ce: Waiting\n",
            "[Skaffold] 47cc65c6dd57: Waiting\n",
            "[Skaffold] 4f874315440c: Layer already exists\n",
            "[Skaffold] f13a156e38fd: Layer already exists\n",
            "[Skaffold] 291bb236dc3f: Layer already exists\n",
            "[Skaffold] 9042e84a180f: Layer already exists\n",
            "[Skaffold] 4058ae03fa32: Layer already exists\n",
            "[Skaffold] d8bc156b2e76: Layer already exists\n",
            "[Skaffold] e3437c61d457: Layer already exists\n",
            "[Skaffold] 572b4b19939e: Layer already exists\n",
            "[Skaffold] 84ff92691f90: Layer already exists\n",
            "[Skaffold] 54b00d861a7a: Layer already exists\n",
            "[Skaffold] c4e66be694ce: Layer already exists\n",
            "[Skaffold] c547358928ab: Layer already exists\n",
            "[Skaffold] 47cc65c6dd57: Layer already exists\n",
            "[Skaffold] d897a7e28378: Pushed\n",
            "[Skaffold] latest: digest: sha256:c34b0dd39eb2f22171e9c234bfb3046948af30bd799365e31aa87cd4df3ba271 size: 3479\n",
            "New container image is built. Target image is available in the build spec file.\n",
            "2020-12-10 23:15:39.838917: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:15:39.838972: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
            "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
            "WARNING:tensorflow:From /home/jupyter/imported/my_pipeline/pipeline/pipeline.py:75: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n",
            "WARNING:absl:The \"input\" argument to the CsvExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n",
            "INFO:absl:Adding upstream dependencies for component CsvExampleGen\n",
            "\u001b[0mPipeline compiled successfully.\n",
            "Pipeline package path: /home/jupyter/imported/my_pipeline/my_pipeline.tar.gz\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/bin/tfx\", line 10, in <module>\n",
            "    sys.exit(cli_group())\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/decorators.py\", line 73, in new_func\n",
            "    return ctx.invoke(f, obj, *args, **kwargs)\n",
            "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/tools/cli/commands/pipeline.py\", line 117, in create_pipeline\n",
            "    handler_factory.create_handler(ctx.flags_dict).create_pipeline()\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/tools/cli/handler/kubeflow_handler.py\", line 91, in create_pipeline\n",
            "    self._save_pipeline(pipeline_args, update=update)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/tfx/tools/cli/handler/kubeflow_handler.py\", line 240, in _save_pipeline\n",
            "    pipeline_name=pipeline_name)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp/_client.py\", line 720, in upload_pipeline\n",
            "    response = self._upload_api.upload_pipeline(pipeline_package_path, name=pipeline_name, description=description)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/api/pipeline_upload_service_api.py\", line 83, in upload_pipeline\n",
            "    return self.upload_pipeline_with_http_info(uploadfile, **kwargs)  # noqa: E501\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/api/pipeline_upload_service_api.py\", line 191, in upload_pipeline_with_http_info\n",
            "    collection_formats=collection_formats)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/api_client.py\", line 383, in call_api\n",
            "    _preload_content, _request_timeout, _host)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/api_client.py\", line 202, in __call_api\n",
            "    raise e\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/api_client.py\", line 199, in __call_api\n",
            "    _request_timeout=_request_timeout)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/api_client.py\", line 427, in request\n",
            "    body=body)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/rest.py\", line 285, in POST\n",
            "    body=body)\n",
            "  File \"/home/jupyter/.local/lib/python3.7/site-packages/kfp_server_api/rest.py\", line 238, in request\n",
            "    raise ApiException(http_resp=r)\n",
            "kfp_server_api.exceptions.ApiException: (403)\n",
            "Reason: Forbidden\n",
            "HTTP response headers: HTTPHeaderDict({'Content-Length': '1449', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Thu, 10 Dec 2020 23:15:43 GMT', 'Vary': 'Origin', 'X-Content-Type-Options': 'nosniff', 'X-Frame-Options': 'SAMEORIGIN', 'X-Xss-Protection': '0', 'Set-Cookie': 'S=cloud_datalab_tunnel=AZ_1xleR-054KnLmqzBjrRvBhC4MV_IhvZnR8grzGYE; Path=/; Max-Age=3600'})\n",
            "HTTP response body: \n",
            "<!DOCTYPE html>\n",
            "<html lang=en>\n",
            "  <meta charset=utf-8>\n",
            "  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\n",
            "  <title>Error 403 (Forbidden)!!1</title>\n",
            "  <style>\n",
            "    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n",
            "  </style>\n",
            "  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n",
            "  <p><b>403.</b> <ins>That’s an error.</ins>\n",
            "  <p>  <ins>That’s all we know.</ins>\n",
            "\n",
            "\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKSjVVsa0oli",
        "outputId": "7bbbcd57-7adf-4e50-a9c4-464335736cbe"
      },
      "source": [
        "!tfx run create --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:17:24.502952: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:17:24.503002: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Creating a run for pipeline: my_pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE-Pqvto0olm",
        "outputId": "528f5365-7914-49da-dd96-dd6c844bed8d"
      },
      "source": [
        "# Update the pipeline\n",
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_dag_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "# You can run the pipeline the same way.\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:17:30.600300: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:17:30.600349: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Updating pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Reading build spec from build.yaml\n",
            "[Skaffold] Generating tags...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline -> gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] Checking cache...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline: Not found. Building\n",
            "[Skaffold] Building [gcr.io/wise-key-298220/tfx-pipeline]...\n",
            "Sending build context to Docker daemon  2.066MBon    534kB\n",
            "[Skaffold] Step 1/4 : FROM tensorflow/tfx:0.23.0\n",
            "[Skaffold]  ---> f8355268ae44\n",
            "[Skaffold] Step 2/4 : WORKDIR /pipeline\n",
            "[Skaffold]  ---> Using cache\n",
            "[Skaffold]  ---> 442cedb2b308\n",
            "[Skaffold] Step 3/4 : COPY ./ ./\n",
            "[Skaffold]  ---> 7bf35f1cbac0\n",
            "[Skaffold] Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
            "[Skaffold]  ---> Running in 06bbbe67b9a7\n",
            "[Skaffold]  ---> b63e330342d4\n",
            "[Skaffold] Successfully built b63e330342d4\n",
            "[Skaffold] Successfully tagged gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] The push refers to repository [gcr.io/wise-key-298220/tfx-pipeline]\n",
            "[Skaffold] 2841d040e45c: Preparing\n",
            "[Skaffold] 291bb236dc3f: Preparing\n",
            "[Skaffold] 9042e84a180f: Preparing\n",
            "[Skaffold] 4f874315440c: Preparing\n",
            "[Skaffold] f13a156e38fd: Preparing\n",
            "[Skaffold] 572b4b19939e: Preparing\n",
            "[Skaffold] d8bc156b2e76: Preparing\n",
            "[Skaffold] 4058ae03fa32: Preparing\n",
            "[Skaffold] e3437c61d457: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] 54b00d861a7a: Preparing\n",
            "[Skaffold] c547358928ab: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] c4e66be694ce: Preparing\n",
            "[Skaffold] 47cc65c6dd57: Preparing\n",
            "[Skaffold] 84ff92691f90: Waiting\n",
            "[Skaffold] 54b00d861a7a: Waiting\n",
            "[Skaffold] 572b4b19939e: Waiting\n",
            "[Skaffold] d8bc156b2e76: Waiting\n",
            "[Skaffold] 4058ae03fa32: Waiting\n",
            "[Skaffold] c547358928ab: Waiting\n",
            "[Skaffold] e3437c61d457: Waiting\n",
            "[Skaffold] c4e66be694ce: Waiting\n",
            "[Skaffold] f13a156e38fd: Layer already exists\n",
            "[Skaffold] 4f874315440c: Layer already exists\n",
            "[Skaffold] 291bb236dc3f: Layer already exists\n",
            "[Skaffold] 9042e84a180f: Layer already exists\n",
            "[Skaffold] d8bc156b2e76: Layer already exists\n",
            "[Skaffold] 4058ae03fa32: Layer already exists\n",
            "[Skaffold] 572b4b19939e: Layer already exists\n",
            "[Skaffold] e3437c61d457: Layer already exists\n",
            "[Skaffold] 54b00d861a7a: Layer already exists\n",
            "[Skaffold] c4e66be694ce: Layer already exists\n",
            "[Skaffold] c547358928ab: Layer already exists\n",
            "[Skaffold] 84ff92691f90: Layer already exists\n",
            "[Skaffold] 47cc65c6dd57: Layer already exists\n",
            "[Skaffold] 2841d040e45c: Pushed\n",
            "[Skaffold] latest: digest: sha256:0c4cc2f46ef1b8191468fe6e9e934e883f4e4c85ebadcb3de9d287ed84d54bc9 size: 3479\n",
            "New container image is built. Target image is available in the build spec file.\n",
            "2020-12-10 23:17:49.581611: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:17:49.581663: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
            "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
            "WARNING:tensorflow:From /home/jupyter/imported/my_pipeline/pipeline/pipeline.py:75: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n",
            "WARNING:absl:The \"input\" argument to the CsvExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n",
            "INFO:absl:Adding upstream dependencies for component CsvExampleGen\n",
            "\u001b[0mPipeline compiled successfully.\n",
            "Pipeline package path: /home/jupyter/imported/my_pipeline/my_pipeline.tar.gz\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m2020-12-10 23:17:54.571994: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:17:54.572048: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Creating a run for pipeline: my_pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQDNitkH0olq",
        "outputId": "5db93687-8c56-4fbc-aa7f-43359e745d1d"
      },
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_dag_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:20:20.737497: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:20:20.737551: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Updating pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Reading build spec from build.yaml\n",
            "[Skaffold] Generating tags...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline -> gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] Checking cache...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline: Not found. Building\n",
            "[Skaffold] Building [gcr.io/wise-key-298220/tfx-pipeline]...\n",
            "Sending build context to Docker daemon  2.066MBon    534kB\n",
            "[Skaffold] Step 1/4 : FROM tensorflow/tfx:0.23.0\n",
            "[Skaffold]  ---> f8355268ae44\n",
            "[Skaffold] Step 2/4 : WORKDIR /pipeline\n",
            "[Skaffold]  ---> Using cache\n",
            "[Skaffold]  ---> 442cedb2b308\n",
            "[Skaffold] Step 3/4 : COPY ./ ./\n",
            "[Skaffold]  ---> 4bebd6af4aa0\n",
            "[Skaffold] Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
            "[Skaffold]  ---> Running in ddc0aa23fa1f\n",
            "[Skaffold]  ---> 11309ed54508\n",
            "[Skaffold] Successfully built 11309ed54508\n",
            "[Skaffold] Successfully tagged gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] The push refers to repository [gcr.io/wise-key-298220/tfx-pipeline]\n",
            "[Skaffold] f41b100cbc38: Preparing\n",
            "[Skaffold] 291bb236dc3f: Preparing\n",
            "[Skaffold] 9042e84a180f: Preparing\n",
            "[Skaffold] 4f874315440c: Preparing\n",
            "[Skaffold] f13a156e38fd: Preparing\n",
            "[Skaffold] 572b4b19939e: Preparing\n",
            "[Skaffold] d8bc156b2e76: Preparing\n",
            "[Skaffold] 4058ae03fa32: Preparing\n",
            "[Skaffold] e3437c61d457: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] 54b00d861a7a: Preparing\n",
            "[Skaffold] c547358928ab: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] c4e66be694ce: Preparing\n",
            "[Skaffold] 47cc65c6dd57: Preparing\n",
            "[Skaffold] 572b4b19939e: Waiting\n",
            "[Skaffold] d8bc156b2e76: Waiting\n",
            "[Skaffold] 4058ae03fa32: Waiting\n",
            "[Skaffold] e3437c61d457: Waiting\n",
            "[Skaffold] 84ff92691f90: Waiting\n",
            "[Skaffold] 54b00d861a7a: Waiting\n",
            "[Skaffold] c547358928ab: Waiting\n",
            "[Skaffold] c4e66be694ce: Waiting\n",
            "[Skaffold] 47cc65c6dd57: Waiting\n",
            "[Skaffold] 4f874315440c: Layer already exists\n",
            "[Skaffold] 291bb236dc3f: Layer already exists\n",
            "[Skaffold] 9042e84a180f: Layer already exists\n",
            "[Skaffold] f13a156e38fd: Layer already exists\n",
            "[Skaffold] d8bc156b2e76: Layer already exists\n",
            "[Skaffold] 572b4b19939e: Layer already exists\n",
            "[Skaffold] 4058ae03fa32: Layer already exists\n",
            "[Skaffold] e3437c61d457: Layer already exists\n",
            "[Skaffold] c547358928ab: Layer already exists\n",
            "[Skaffold] 84ff92691f90: Layer already exists\n",
            "[Skaffold] c4e66be694ce: Layer already exists\n",
            "[Skaffold] 54b00d861a7a: Layer already exists\n",
            "[Skaffold] 47cc65c6dd57: Layer already exists\n",
            "[Skaffold] f41b100cbc38: Pushed\n",
            "[Skaffold] latest: digest: sha256:fd8630e03fc2d8583b778b0bc68020cfae90728364d875717996c942a715566f size: 3479\n",
            "New container image is built. Target image is available in the build spec file.\n",
            "2020-12-10 23:20:39.566292: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:20:39.566350: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
            "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
            "WARNING:tensorflow:From /home/jupyter/imported/my_pipeline/pipeline/pipeline.py:75: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n",
            "WARNING:absl:The \"input\" argument to the CsvExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n",
            "INFO:absl:Adding upstream dependencies for component CsvExampleGen\n",
            "\u001b[0mPipeline compiled successfully.\n",
            "Pipeline package path: /home/jupyter/imported/my_pipeline/my_pipeline.tar.gz\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m2020-12-10 23:20:44.707717: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:20:44.707772: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Creating a run for pipeline: my_pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sD3NxB60olt",
        "outputId": "45077089-e1fd-4ee8-fd2d-2467239700bd"
      },
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_dag_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:20:57.541288: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:20:57.541346: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Updating pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Reading build spec from build.yaml\n",
            "[Skaffold] Generating tags...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline -> gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] Checking cache...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline: Not found. Building\n",
            "[Skaffold] Building [gcr.io/wise-key-298220/tfx-pipeline]...\n",
            "Sending build context to Docker daemon  2.066MBon    534kB\n",
            "[Skaffold] Step 1/4 : FROM tensorflow/tfx:0.23.0\n",
            "[Skaffold]  ---> f8355268ae44\n",
            "[Skaffold] Step 2/4 : WORKDIR /pipeline\n",
            "[Skaffold]  ---> Using cache\n",
            "[Skaffold]  ---> 442cedb2b308\n",
            "[Skaffold] Step 3/4 : COPY ./ ./\n",
            "[Skaffold]  ---> 3e65ecd8ec05\n",
            "[Skaffold] Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
            "[Skaffold]  ---> Running in 9ceb7c5081c8\n",
            "[Skaffold]  ---> 3c750be1db89\n",
            "[Skaffold] Successfully built 3c750be1db89\n",
            "[Skaffold] Successfully tagged gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] The push refers to repository [gcr.io/wise-key-298220/tfx-pipeline]\n",
            "[Skaffold] 7619791dc3eb: Preparing\n",
            "[Skaffold] 291bb236dc3f: Preparing\n",
            "[Skaffold] 9042e84a180f: Preparing\n",
            "[Skaffold] 4f874315440c: Preparing\n",
            "[Skaffold] f13a156e38fd: Preparing\n",
            "[Skaffold] 572b4b19939e: Preparing\n",
            "[Skaffold] d8bc156b2e76: Preparing\n",
            "[Skaffold] 4058ae03fa32: Preparing\n",
            "[Skaffold] e3437c61d457: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] 54b00d861a7a: Preparing\n",
            "[Skaffold] c547358928ab: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] c4e66be694ce: Preparing\n",
            "[Skaffold] 47cc65c6dd57: Preparing\n",
            "[Skaffold] 572b4b19939e: Waiting\n",
            "[Skaffold] d8bc156b2e76: Waiting\n",
            "[Skaffold] 4058ae03fa32: Waiting\n",
            "[Skaffold] e3437c61d457: Waiting\n",
            "[Skaffold] 84ff92691f90: Waiting\n",
            "[Skaffold] 54b00d861a7a: Waiting\n",
            "[Skaffold] c547358928ab: Waiting\n",
            "[Skaffold] c4e66be694ce: Waiting\n",
            "[Skaffold] 47cc65c6dd57: Waiting\n",
            "[Skaffold] 291bb236dc3f: Layer already exists\n",
            "[Skaffold] f13a156e38fd: Layer already exists\n",
            "[Skaffold] 9042e84a180f: Layer already exists\n",
            "[Skaffold] 4f874315440c: Layer already exists\n",
            "[Skaffold] 4058ae03fa32: Layer already exists\n",
            "[Skaffold] 572b4b19939e: Layer already exists\n",
            "[Skaffold] e3437c61d457: Layer already exists\n",
            "[Skaffold] d8bc156b2e76: Layer already exists\n",
            "[Skaffold] 84ff92691f90: Layer already exists\n",
            "[Skaffold] c4e66be694ce: Layer already exists\n",
            "[Skaffold] 54b00d861a7a: Layer already exists\n",
            "[Skaffold] c547358928ab: Layer already exists\n",
            "[Skaffold] 47cc65c6dd57: Layer already exists\n",
            "[Skaffold] 7619791dc3eb: Pushed\n",
            "[Skaffold] latest: digest: sha256:89f0a335ed5c0ea6fceca870ca4b748254d209e8ba2ad401adc18e9f2a972cdd size: 3479\n",
            "New container image is built. Target image is available in the build spec file.\n",
            "2020-12-10 23:21:17.395222: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:21:17.395277: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
            "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
            "WARNING:tensorflow:From /home/jupyter/imported/my_pipeline/pipeline/pipeline.py:75: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n",
            "WARNING:absl:The \"input\" argument to the CsvExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n",
            "INFO:absl:Adding upstream dependencies for component CsvExampleGen\n",
            "\u001b[0mPipeline compiled successfully.\n",
            "Pipeline package path: /home/jupyter/imported/my_pipeline/my_pipeline.tar.gz\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m2020-12-10 23:21:22.469979: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:21:22.470033: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Creating a run for pipeline: my_pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3HVPcKi0olw",
        "outputId": "4df04484-1448-4581-ff15-d06754222a4c"
      },
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_dag_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:23:20.023905: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:23:20.023955: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Updating pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Reading build spec from build.yaml\n",
            "[Skaffold] Generating tags...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline -> gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] Checking cache...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline: Not found. Building\n",
            "[Skaffold] Building [gcr.io/wise-key-298220/tfx-pipeline]...\n",
            "Sending build context to Docker daemon  2.066MBon    534kB\n",
            "[Skaffold] Step 1/4 : FROM tensorflow/tfx:0.23.0\n",
            "[Skaffold]  ---> f8355268ae44\n",
            "[Skaffold] Step 2/4 : WORKDIR /pipeline\n",
            "[Skaffold]  ---> Using cache\n",
            "[Skaffold]  ---> 442cedb2b308\n",
            "[Skaffold] Step 3/4 : COPY ./ ./\n",
            "[Skaffold]  ---> 952a11032bb5\n",
            "[Skaffold] Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
            "[Skaffold]  ---> Running in b505e6959038\n",
            "[Skaffold]  ---> 8184ce2466f9\n",
            "[Skaffold] Successfully built 8184ce2466f9\n",
            "[Skaffold] Successfully tagged gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] The push refers to repository [gcr.io/wise-key-298220/tfx-pipeline]\n",
            "[Skaffold] b3bc0123d6d6: Preparing\n",
            "[Skaffold] 291bb236dc3f: Preparing\n",
            "[Skaffold] 9042e84a180f: Preparing\n",
            "[Skaffold] 4f874315440c: Preparing\n",
            "[Skaffold] f13a156e38fd: Preparing\n",
            "[Skaffold] 572b4b19939e: Preparing\n",
            "[Skaffold] d8bc156b2e76: Preparing\n",
            "[Skaffold] 4058ae03fa32: Preparing\n",
            "[Skaffold] e3437c61d457: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] 54b00d861a7a: Preparing\n",
            "[Skaffold] c547358928ab: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] c4e66be694ce: Preparing\n",
            "[Skaffold] 47cc65c6dd57: Preparing\n",
            "[Skaffold] 572b4b19939e: Waiting\n",
            "[Skaffold] 84ff92691f90: Waiting\n",
            "[Skaffold] 54b00d861a7a: Waiting\n",
            "[Skaffold] d8bc156b2e76: Waiting\n",
            "[Skaffold] c547358928ab: Waiting\n",
            "[Skaffold] 4058ae03fa32: Waiting\n",
            "[Skaffold] e3437c61d457: Waiting\n",
            "[Skaffold] c4e66be694ce: Waiting\n",
            "[Skaffold] 47cc65c6dd57: Waiting\n",
            "[Skaffold] f13a156e38fd: Layer already exists\n",
            "[Skaffold] 4f874315440c: Layer already exists\n",
            "[Skaffold] 9042e84a180f: Layer already exists\n",
            "[Skaffold] 291bb236dc3f: Layer already exists\n",
            "[Skaffold] 572b4b19939e: Layer already exists\n",
            "[Skaffold] d8bc156b2e76: Layer already exists\n",
            "[Skaffold] e3437c61d457: Layer already exists\n",
            "[Skaffold] 4058ae03fa32: Layer already exists\n",
            "[Skaffold] c4e66be694ce: Layer already exists\n",
            "[Skaffold] 84ff92691f90: Layer already exists\n",
            "[Skaffold] 54b00d861a7a: Layer already exists\n",
            "[Skaffold] c547358928ab: Layer already exists\n",
            "[Skaffold] 47cc65c6dd57: Layer already exists\n",
            "[Skaffold] b3bc0123d6d6: Pushed\n",
            "[Skaffold] latest: digest: sha256:8f1cf1c98b173231d5a8906109c754a477016184a69740e61723bfbd918a4782 size: 3479\n",
            "New container image is built. Target image is available in the build spec file.\n",
            "2020-12-10 23:23:38.998285: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:23:38.998339: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
            "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
            "WARNING:tensorflow:From /home/jupyter/imported/my_pipeline/pipeline/pipeline.py:75: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n",
            "WARNING:absl:The \"input\" argument to the CsvExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n",
            "INFO:absl:Adding upstream dependencies for component CsvExampleGen\n",
            "\u001b[0mPipeline compiled successfully.\n",
            "Pipeline package path: /home/jupyter/imported/my_pipeline/my_pipeline.tar.gz\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m2020-12-10 23:23:43.954226: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:23:43.954278: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Creating a run for pipeline: my_pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxOjhBmG0ol0",
        "outputId": "67bb027c-8296-47ec-9acf-4847ec6b2b79"
      },
      "source": [
        "!tfx pipeline update \\\n",
        "--pipeline-path=kubeflow_dag_runner.py \\\n",
        "--endpoint={ENDPOINT}\n",
        "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 23:26:52.292433: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:26:52.292500: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Updating pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Reading build spec from build.yaml\n",
            "[Skaffold] Generating tags...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline -> gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] Checking cache...\n",
            "[Skaffold]  - gcr.io/wise-key-298220/tfx-pipeline: Not found. Building\n",
            "[Skaffold] Building [gcr.io/wise-key-298220/tfx-pipeline]...\n",
            "Sending build context to Docker daemon  2.066MBon    534kB\n",
            "[Skaffold] Step 1/4 : FROM tensorflow/tfx:0.23.0\n",
            "[Skaffold]  ---> f8355268ae44\n",
            "[Skaffold] Step 2/4 : WORKDIR /pipeline\n",
            "[Skaffold]  ---> Using cache\n",
            "[Skaffold]  ---> 442cedb2b308\n",
            "[Skaffold] Step 3/4 : COPY ./ ./\n",
            "[Skaffold]  ---> ca0722952e7a\n",
            "[Skaffold] Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
            "[Skaffold]  ---> Running in 3d9bdcaa2fa2\n",
            "[Skaffold]  ---> 5d1224278b54\n",
            "[Skaffold] Successfully built 5d1224278b54\n",
            "[Skaffold] Successfully tagged gcr.io/wise-key-298220/tfx-pipeline:latest\n",
            "[Skaffold] The push refers to repository [gcr.io/wise-key-298220/tfx-pipeline]\n",
            "[Skaffold] 4dfd0db93b67: Preparing\n",
            "[Skaffold] 291bb236dc3f: Preparing\n",
            "[Skaffold] 9042e84a180f: Preparing\n",
            "[Skaffold] 4f874315440c: Preparing\n",
            "[Skaffold] f13a156e38fd: Preparing\n",
            "[Skaffold] 572b4b19939e: Preparing\n",
            "[Skaffold] d8bc156b2e76: Preparing\n",
            "[Skaffold] 4058ae03fa32: Preparing\n",
            "[Skaffold] e3437c61d457: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] 54b00d861a7a: Preparing\n",
            "[Skaffold] c547358928ab: Preparing\n",
            "[Skaffold] 84ff92691f90: Preparing\n",
            "[Skaffold] c4e66be694ce: Preparing\n",
            "[Skaffold] 47cc65c6dd57: Preparing\n",
            "[Skaffold] 572b4b19939e: Waiting\n",
            "[Skaffold] d8bc156b2e76: Waiting\n",
            "[Skaffold] 4058ae03fa32: Waiting\n",
            "[Skaffold] e3437c61d457: Waiting\n",
            "[Skaffold] 84ff92691f90: Waiting\n",
            "[Skaffold] 54b00d861a7a: Waiting\n",
            "[Skaffold] c547358928ab: Waiting\n",
            "[Skaffold] c4e66be694ce: Waiting\n",
            "[Skaffold] 47cc65c6dd57: Waiting\n",
            "[Skaffold] 291bb236dc3f: Layer already exists\n",
            "[Skaffold] 9042e84a180f: Layer already exists\n",
            "[Skaffold] 4f874315440c: Layer already exists\n",
            "[Skaffold] f13a156e38fd: Layer already exists\n",
            "[Skaffold] d8bc156b2e76: Layer already exists\n",
            "[Skaffold] 572b4b19939e: Layer already exists\n",
            "[Skaffold] 4058ae03fa32: Layer already exists\n",
            "[Skaffold] c547358928ab: Layer already exists\n",
            "[Skaffold] e3437c61d457: Layer already exists\n",
            "[Skaffold] 84ff92691f90: Layer already exists\n",
            "[Skaffold] 54b00d861a7a: Layer already exists\n",
            "[Skaffold] 47cc65c6dd57: Layer already exists\n",
            "[Skaffold] c4e66be694ce: Layer already exists\n",
            "[Skaffold] 4dfd0db93b67: Pushed\n",
            "[Skaffold] latest: digest: sha256:99b340c282ce6d51bb17626bce4c0b4afeef34ca9951ff2c1d10b6b24af8b866 size: 3479\n",
            "New container image is built. Target image is available in the build spec file.\n",
            "2020-12-10 23:27:11.088945: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:27:11.088998: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
            "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
            "WARNING:tensorflow:From /home/jupyter/imported/my_pipeline/pipeline/pipeline.py:75: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n",
            "WARNING:absl:The \"input\" argument to the CsvExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n",
            "INFO:absl:Adding upstream dependencies for component CsvExampleGen\n",
            "\u001b[0mPipeline compiled successfully.\n",
            "Pipeline package path: /home/jupyter/imported/my_pipeline/my_pipeline.tar.gz\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m2020-12-10 23:27:16.116787: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2020-12-10 23:27:16.116845: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "CLI\n",
            "Creating a run for pipeline: my_pipeline\n",
            "Detected Kubeflow.\n",
            "Use --engine flag if you intend to use a different orchestrator.\n",
            "Pipeline \"my_pipeline\" does not exist.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EJt9N1Kt13v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}