{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"components_keras.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"as4OTe2ukSqm"},"source":["# upgrade pip\n","try:\n","  import colab\n","  !pip install --upgrade pip\n","except:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4SQA7Q5nej3"},"source":["# install TFX\n","!pip install -q -U --use-feature=2020-resolver tfx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIqpWK9efviJ"},"source":["# restart notebook\n","\n","# install libraries\n","import os\n","import pprint\n","import tempfile\n","import urllib\n","\n","import absl\n","import tensorflow as tf\n","import tensorflow_model_analysis as tfma\n","tf.get_logger().propagate = False\n","pp = pprint.PrettyPrinter()\n","\n","import tfx\n","from tfx.components import CsvExampleGen\n","from tfx.components import Evaluator\n","from tfx.components import ExampleValidator\n","from tfx.components import Pusher\n","from tfx.components import ResolverNode\n","from tfx.components import SchemaGen\n","from tfx.components import StatisticsGen\n","from tfx.components import Trainer\n","from tfx.components import Transform\n","from tfx.components.base import executor_spec\n","from tfx.components.trainer.executor import GenericExecutor\n","from tfx.dsl.experimental import latest_blessed_modelresolver\n","from tfx.orchestration import metadata\n","from tfx.orchestration import pipeline\n","from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n","from tfx.proto import pusher_pb2\n","from tfx.proto import trainer_pb2\n","from tfx.types import Channel\n","from tfx.types.standard_artifacts import Model\n","from tfx.types.standard_artifacts import ModelBlessing\n","from tfx.utils.dsl_utils import external_input\n","\n","\n","%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZ4K18_DN2D8"},"source":["# check the library versions\n","print('TensorFlow version: {}'.format(tf.__version__))\n","print('TFX version: {}'.format(tfx.__version__))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ad5JLpKbf6sN"},"source":["# set pipeline paths \n","\n","# root package\n","tfxroot = tfx.__path__[0]\n","\n","# taxi example \n","taxiroot = os.path.join(tfxroot, 'examples/chicago_taxi_pipeline')\n","\n","# path where model will be serving \n","servingmodeldir = os.path.join(\n","    tempfile.mkdtemp(), 'serving_model/taxi_simple')\n","\n","# logging \n","absl.logging.set_verbosity(absl.logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BywX6OUEhAqn"},"source":["# download dataset\n","dataroot = tempfile.mkdtemp(prefix='tfx-data')\n","DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv'\n","datafilepath = os.path.join(dataroot, \"data.csv\")\n","urllib.request.urlretrieve(DATA_PATH, datafilepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5YPeLPFOXaD"},"source":["# check csv file \n","!head {datafilepath}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Rh6K5sUf9dd"},"source":["# setup interactivecontext\n","context = InteractiveContext()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PyXjuMt8f-9u"},"source":["# setup ExampleGen\n","examplegen = CsvExampleGen(input=external_input(dataroot))\n","context.run(examplegen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"880KkTAkPeUg"},"source":["# check the artifacts \n","artifact = examplegen.outputs['examples'].get()[0]\n","print(artifact.split_names, artifact.uri)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4XIXjiCPwzQ"},"source":["# URI of the output artifact having training examples\n","trainuri = os.path.join(examplegen.outputs['examples'].get()[0].uri, 'train')\n","\n","# get the files \n","tfrecordfilenames = [os.path.join(trainuri, name)\n","                      for name in os.listdir(trainuri)]\n","\n","# setup TFRecordDataset\n","dataset = tf.data.TFRecordDataset(tfrecordfilenames, compression_type=\"GZIP\")\n","\n","# loop over 3 examples \n","for tfrecord in dataset.take(3):\n","  serializedexample = tfrecord.numpy()\n","  example = tf.train.Example()\n","  example.ParseFromString(serializedexample)\n","  pp.pprint(example)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAscCCYWgA-9"},"source":["# setup StatisticsGen\n","statisticsgen = StatisticsGen(\n","    examples=examplegen.outputs['examples'])\n","context.run(statisticsgen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLjXy7K6Tp_G"},"source":["# visualise the output statistics \n","context.show(statisticsgen.outputs['statistics'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ygQvZ6hsiQ_J"},"source":["# setup SchemaGen \n","schemagen = SchemaGen(\n","    statistics=statisticsgen.outputs['statistics'],\n","    infer_feature_shape=False)\n","context.run(schemagen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ec9vqDXpXeMb"},"source":["# visualise generated schema as a table \n","context.show(schemagen.outputs['schema'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRlRUuGgiXks"},"source":["# setup ExampleValidator\n","examplevalidator = ExampleValidator(\n","    statistics=statisticsgen.outputs['statistics'],\n","    schema=schemagen.outputs['schema'])\n","context.run(examplevalidator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDyAAozQcrk3"},"source":["# visualise anomalies as a table \n","context.show(examplevalidator.outputs['anomalies'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuNSiUKb4YJf"},"source":["taxiconstantsfile = 'taxi_constants.py'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPjhXuIF4YJh"},"source":["%%writefile {taxiconstantsfile}\n","\n","# max value of categorical features \n","MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n","\n","# feature keys \n","CATEGORICAL_FEATURE_KEYS = [\n","    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n","    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n","    'dropoff_community_area'\n","]\n","\n","DENSE_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n","\n","# number of buckets for encoding \n","FEATURE_BUCKET_COUNT = 10\n","\n","BUCKET_FEATURE_KEYS = [\n","    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n","    'dropoff_longitude'\n","]\n","\n","# number of vocabulary terms \n","VOCAB_SIZE = 1000\n","\n","# count of out of vocabulary buckets \n","OOV_SIZE = 10\n","\n","VOCAB_FEATURE_KEYS = [\n","    'payment_type',\n","    'company',\n","]\n","\n","LABEL_KEY = 'tips'\n","FARE_KEY = 'fare'\n","\n","def transformed_name(key):\n","  return key + '_xf'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AJ9hBs94YJm"},"source":["_taxi_transform_module_file = 'taxi_transform.py'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYmxxx9A4YJn"},"source":["# write function to take raw data as input and return transformed features\n","%%writefile {_taxi_transform_module_file}\n","\n","import tensorflow as tf\n","import tensorflow_transform as tft\n","\n","import taxi_constants\n","\n","_DENSE_FEATURE_KEYS = taxi_constants.DENSE_FEATURE_KEYS\n","_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n","_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n","_OOV_SIZE = taxi_constants.OOV_SIZE\n","_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n","_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n","_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n","_FARE_KEY = taxi_constants.FARE_KEY\n","_LABEL_KEY = taxi_constants.LABEL_KEY\n","_transformed_name = taxi_constants.transformed_name\n","\n","\n","def preprocessing_fn(inputs):\n"," \n","  outputs = {}\n","  for key in _DENSE_FEATURE_KEYS:\n","    # dense float set nan's to the mean.\n","    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n","        fillinmissing(inputs[key]))\n","\n","  for key in _VOCAB_FEATURE_KEYS:\n","    # vocabulary for feature.\n","    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n","        fillinmissing(inputs[key]),\n","        top_k=_VOCAB_SIZE,\n","        num_oov_buckets=_OOV_SIZE)\n","\n","  for key in _BUCKET_FEATURE_KEYS:\n","    outputs[_transformed_name(key)] = tft.bucketize(\n","        fillinmissing(inputs[key]), _FEATURE_BUCKET_COUNT)\n","\n","  for key in _CATEGORICAL_FEATURE_KEYS:\n","    outputs[_transformed_name(key)] = fillinmissing(inputs[key])\n","\n","  # did the customer give big tip\n","  taxi_fare = fillinmissing(inputs[_FARE_KEY])\n","  tips = fillinmissing(inputs[_LABEL_KEY])\n","  outputs[_transformed_name(_LABEL_KEY)] = tf.where(\n","      tf.math.is_nan(taxi_fare),\n","      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n","      # tip >20% fare \n","      tf.cast(\n","          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n","\n","  return outputs\n","\n","\n","def fillinmissing(x):\n","  default_value = '' if x.dtype == tf.string else 0\n","  return tf.squeeze(\n","      tf.sparse.to_dense(\n","          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n","          default_value),\n","      axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHfhth_GiZI9"},"source":["# transform component \n","transform = Transform(\n","    examples=examplegen.outputs['examples'],\n","    schema=schemagen.outputs['schema'],\n","    module_file=os.path.abspath(_taxi_transform_module_file))\n","context.run(transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SClrAaEGR1O5"},"source":["# transform artifacts \n","transform.outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tRw4DneR3i7"},"source":["# transform graph artifact \n","trainuri = transform.outputs['transform_graph'].get()[0].uri\n","os.listdir(trainuri)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwbW2zPKR_S4"},"source":["# Get the URI of the output artifact representing the transformed examples\n","trainuri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'train')\n","\n","# list of files \n","tfrecordfilenames = [os.path.join(trainuri, name)\n","                      for name in os.listdir(trainuri)]\n","\n","# Create TFRecordDataset\n","dataset = tf.data.TFRecordDataset(tfrecordfilenames, compression_type=\"GZIP\")\n","\n","# Iterate over the first 3 records and decode them.\n","for tfrecord in dataset.take(3):\n","  serializedexample = tfrecord.numpy()\n","  example = tf.train.Example()\n","  example.ParseFromString(serializedexample)\n","  pp.pprint(example)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1376oq04YJt"},"source":["taxitrainermodulefile = 'taxi_trainer.py'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nf9UuNng4YJu"},"source":["%%writefile {taxitrainermodulefile}\n","\n","from typing import List, Text\n","\n","import os\n","import absl\n","import datetime\n","import tensorflow as tf\n","import tensorflow_transform as tft\n","\n","from tfx.components.trainer.executor import TrainerFnArgs\n","from tfx.components.trainer.fn_args_utils import DataAccessor\n","from tfx_bsl.tfxio import dataset_options\n","\n","import taxi_constants\n","\n","_DENSE_FEATURE_KEYS = taxi_constants.DENSE_FEATURE_KEYS\n","_VOCAB_FEATURE_KEYS = taxi_constants.VOCAB_FEATURE_KEYS\n","_VOCAB_SIZE = taxi_constants.VOCAB_SIZE\n","_OOV_SIZE = taxi_constants.OOV_SIZE\n","_FEATURE_BUCKET_COUNT = taxi_constants.FEATURE_BUCKET_COUNT\n","_BUCKET_FEATURE_KEYS = taxi_constants.BUCKET_FEATURE_KEYS\n","_CATEGORICAL_FEATURE_KEYS = taxi_constants.CATEGORICAL_FEATURE_KEYS\n","_MAX_CATEGORICAL_FEATURE_VALUES = taxi_constants.MAX_CATEGORICAL_FEATURE_VALUES\n","_LABEL_KEY = taxi_constants.LABEL_KEY\n","_transformed_name = taxi_constants.transformed_name\n","\n","\n","def transformednames(keys):\n","  return [_transformed_name(key) for key in keys]\n","\n","\n","def getservetfexamplesfn(model, tf_transform_output):\n","\n","  model.tft_layer = tf_transform_output.transform_features_layer()\n","\n","  @tf.function\n","  def serve_tf_examples_fn(serialized_tf_examples):\n","    feature_spec = tf_transform_output.raw_feature_spec()\n","    feature_spec.pop(_LABEL_KEY)\n","    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n","    transformed_features = model.tft_layer(parsed_features)\n","    return model(transformed_features)\n","\n","  return serve_tf_examples_fn\n","\n","\n","def _input_fn(file_pattern: List[Text],\n","              data_accessor: DataAccessor,\n","              tf_transform_output: tft.TFTransformOutput,\n","              batch_size: int = 200) -> tf.data.Dataset:\n","  \n","  return data_accessor.tf_dataset_factory(\n","      file_pattern,\n","      dataset_options.TensorFlowDatasetOptions(\n","          batch_size=batch_size, label_key=_transformed_name(_LABEL_KEY)),\n","      tf_transform_output.transformed_metadata.schema)\n","\n","\n","def buildkerasmodel(hidden_units: List[int] = None) -> tf.keras.Model:\n","\n","  real_valued_columns = [\n","      tf.feature_column.numeric_column(key, shape=())\n","      for key in transformednames(_DENSE_FEATURE_KEYS)\n","  ]\n","  categorical_columns = [\n","      tf.feature_column.categorical_column_with_identity(\n","          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n","      for key in transformednames(_VOCAB_FEATURE_KEYS)\n","  ]\n","  categorical_columns += [\n","      tf.feature_column.categorical_column_with_identity(\n","          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n","      for key in transformednames(_BUCKET_FEATURE_KEYS)\n","  ]\n","  categorical_columns += [\n","      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n","          key,\n","          num_buckets=num_buckets,\n","          default_value=0) for key, num_buckets in zip(\n","              transformednames(_CATEGORICAL_FEATURE_KEYS),\n","              _MAX_CATEGORICAL_FEATURE_VALUES)\n","  ]\n","  indicator_column = [\n","      tf.feature_column.indicator_column(categorical_column)\n","      for categorical_column in categorical_columns\n","  ]\n","\n","  model = widedeepclassifier(\n","      # TODO(b/139668410) replace with premade wide_and_deep keras model\n","      wide_columns=indicator_column,\n","      deep_columns=real_valued_columns,\n","      dnn_hidden_units=hidden_units or [100, 70, 50, 25])\n","  return model\n","\n","\n","def widedeepclassifier(wide_columns, deep_columns, dnn_hidden_units):\n","\n"," \n","  input_layers = {\n","      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n","      for colname in transformednames(_DENSE_FEATURE_KEYS)\n","  }\n","  input_layers.update({\n","      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n","      for colname in transformednames(_VOCAB_FEATURE_KEYS)\n","  })\n","  input_layers.update({\n","      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n","      for colname in transformednames(_BUCKET_FEATURE_KEYS)\n","  })\n","  input_layers.update({\n","      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n","      for colname in transformednames(_CATEGORICAL_FEATURE_KEYS)\n","  })\n","\n","  deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n","  for numnodes in dnn_hidden_units:\n","    deep = tf.keras.layers.Dense(numnodes)(deep)\n","  wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n","\n","  output = tf.keras.layers.Dense(\n","      1, activation='sigmoid')(\n","          tf.keras.layers.concatenate([deep, wide]))\n","\n","  model = tf.keras.Model(input_layers, output)\n","  model.compile(\n","      loss='binary_crossentropy',\n","      optimizer=tf.keras.optimizers.Adam(lr=0.001),\n","      metrics=[tf.keras.metrics.BinaryAccuracy()])\n","  model.summary(print_fn=absl.logging.info)\n","  return model\n","\n","\n","def run_fn(fn_args: TrainerFnArgs):\n","\n","  first_dnn_layer_size = 100\n","  num_dnn_layers = 4\n","  dnn_decay_factor = 0.7\n","\n","  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n","\n","  train_dataset = _input_fn(fn_args.train_files, fn_args.data_accessor, \n","                            tf_transform_output, 40)\n","  eval_dataset = _input_fn(fn_args.eval_files, fn_args.data_accessor, \n","                           tf_transform_output, 40)\n","\n","  model = buildkerasmodel(\n","      hidden_units=[\n","          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n","          for i in range(num_dnn_layers)\n","      ])\n","\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=fn_args.model_run_dir, update_freq='batch')\n","  model.fit(\n","      train_dataset,\n","      steps_per_epoch=fn_args.train_steps,\n","      validation_data=eval_dataset,\n","      validation_steps=fn_args.eval_steps,\n","      callbacks=[tensorboard_callback])\n","\n","  signatures = {\n","      'serving_default':\n","          getservetfexamplesfn(model,\n","                                    tf_transform_output).get_concrete_function(\n","                                        tf.TensorSpec(\n","                                            shape=[None],\n","                                            dtype=tf.string,\n","                                            name='examples')),\n","  }\n","  model.save(fn_args.serving_modeldir, save_format='tf', signatures=signatures)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"429-vvCWibO0"},"source":["# run the trainer component \n","trainer = Trainer(\n","    module_file=os.path.abspath(taxitrainermodulefile),\n","    custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n","    examples=transform.outputs['transformed_examples'],\n","    transform_graph=transform.outputs['transform_graph'],\n","    schema=schemagen.outputs['schema'],\n","    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n","    eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n","context.run(trainer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXe62WE0S0Ek"},"source":["# analyse training with tensorboard \n","modelartifactdir = trainer.outputs['model'].get()[0].uri\n","pp.pprint(os.listdir(modelartifactdir))\n","modeldir = os.path.join(modelartifactdir, 'serving_modeldir')\n","pp.pprint(os.listdir(modeldir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-APzqz2NeAyj"},"source":["# connect to tensorboard\n","modelrunartifactdir = trainer.outputs['model_run'].get()[0].uri\n","\n","%load_ext tensorboard\n","%tensorboard --logdir {modelrunartifactdir}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVhfzzh9PDEx"},"source":["# evaluator component \n","evalconfig = tfma.EvalConfig(\n","    model_specs=[\n","   \n","        tfma.ModelSpec(label_key='tips')\n","    ],\n","    metrics_specs=[\n","        tfma.MetricsSpec(\n","    \n","            metrics=[\n","                tfma.MetricConfig(class_name='ExampleCount'),\n","                tfma.MetricConfig(class_name='BinaryAccuracy',\n","                  threshold=tfma.MetricThreshold(\n","                      value_threshold=tfma.GenericValueThreshold(\n","                          lower_bound={'value': 0.5}),\n","                      change_threshold=tfma.GenericChangeThreshold(\n","                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n","                          absolute={'value': -1e-10})))\n","            ]\n","        )\n","    ],\n","    slicing_specs=[\n","        tfma.SlicingSpec(),\n","        tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zjcx8g6mihSt"},"source":["# run the evaluator and run it \n","modelresolver = ResolverNode(\n","      instance_name='latest_blessed_modelresolver',\n","      resolver_class=latest_blessed_modelresolver.LatestBlessedModelResolver,\n","      model=Channel(type=Model),\n","      model_blessing=Channel(type=ModelBlessing))\n","context.run(modelresolver)\n","\n","evaluator = Evaluator(\n","    examples=examplegen.outputs['examples'],\n","    model=trainer.outputs['model'],\n","    baseline_model=modelresolver.outputs['model'],\n","    evalconfig=evalconfig)\n","context.run(evaluator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4GghePOTJxL"},"source":["# examine the output artifacts \n","evaluator.outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U729j5X5QQUQ"},"source":["# visualise the global metrics \n","context.show(evaluator.outputs['evaluation'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pyis6iy0HLdi"},"source":["# tensorflow model analysis \n","import tensorflow_model_analysis as tfma\n","\n","# Get the TFMA output result path and load the result.\n","PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n","tfmaresult = tfma.load_eval_result(PATH_TO_RESULT)\n","\n","# Show data sliced along feature column trip_start_hour.\n","tfma.view.render_slicing_metrics(\n","    tfmaresult, slicing_column='trip_start_hour')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZmiRtg6TKtR"},"source":["blessinguri = evaluator.outputs.blessing.get()[0].uri\n","!ls -l {blessinguri}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxa5G08bSJ8a"},"source":["# load validation result record\n","PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n","print(tfma.load_validation_result(PATH_TO_RESULT))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r45nQ69eikc9"},"source":["# define pusher component \n","pusher = Pusher(\n","    model=trainer.outputs['model'],\n","    model_blessing=evaluator.outputs['blessing'],\n","    push_destination=pusher_pb2.PushDestination(\n","        filesystem=pusher_pb2.PushDestination.Filesystem(\n","            base_directory=servingmodeldir)))\n","context.run(pusher)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRkWo-MzTSss"},"source":["# artifacts of pusher component\n","pusher.outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zyIqWl9TSdG"},"source":["pushuri = pusher.outputs.model_push.get()[0].uri\n","model = tf.saved_model.load(pushuri)\n","\n","for item in model.signatures.items():\n","  pp.pprint(item)"],"execution_count":null,"outputs":[]}]}